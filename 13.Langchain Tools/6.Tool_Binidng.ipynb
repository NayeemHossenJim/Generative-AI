{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d7eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d99a1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply_tool(x: int, y: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed13981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'title': 'X', 'type': 'integer'},\n",
       " 'y': {'title': 'Y', 'type': 'integer'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce8abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatGroq(groq_api_key=os.environ.get(\"GROQ_API_KEY\"), model=\"openai/gpt-oss-120b\", temperature=1.2)\n",
    "LLM_with_tool = LLM.bind_tools([multiply_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89161dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey there! Iâ€™m doing great, thanks for asking. How can I help you today?', additional_kwargs={'reasoning_content': 'User says \"Hi how are you\". It\\'s a greeting, simple. Should respond politely.'}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 125, 'total_tokens': 172, 'completion_time': 0.09536686, 'prompt_time': 0.021061509, 'queue_time': 0.04361735, 'total_time': 0.116428369}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_91af62a853', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--89a4e6ca-dd3f-413e-bb8b-327ed6474060-0', usage_metadata={'input_tokens': 125, 'output_tokens': 47, 'total_tokens': 172})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_with_tool.invoke('Hi how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9374c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = HumanMessage('can you multiply 3 with 1000')\n",
    "messages = [query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b43d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = LLM_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ffaabe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='can you multiply 3 with 1000', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'reasoning_content': \"The user asks to multiply 3 with 1000. Simple. I can compute 3000. I could also use the provided function multiply_tool. Let's do that.\", 'tool_calls': [{'id': 'fc_fab5f9e8-ae2f-47a3-8f8c-2494e1926408', 'function': {'arguments': '{\"x\":3,\"y\":1000}', 'name': 'multiply_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 130, 'total_tokens': 201, 'completion_time': 0.141138727, 'prompt_time': 0.010046498, 'queue_time': 0.043520827, 'total_time': 0.151185225}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_4913bcd64f', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--18e6f0f8-e6db-47b3-b30c-b40ce2d15b91-0', tool_calls=[{'name': 'multiply_tool', 'args': {'x': 3, 'y': 1000}, 'id': 'fc_fab5f9e8-ae2f-47a3-8f8c-2494e1926408', 'type': 'tool_call'}], usage_metadata={'input_tokens': 130, 'output_tokens': 71, 'total_tokens': 201})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(result)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7b2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_result = multiply_tool.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839c25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(tool_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794fa3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The product of 3 and 1000 is **3000**.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_with_tool.invoke(messages).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
