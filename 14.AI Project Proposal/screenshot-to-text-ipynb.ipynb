{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Generative-AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from docx import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage\n",
    "import logging\n",
    "\n",
    "# Logging configuration\n",
    "LOG_LEVEL = os.getenv(\"LOG_LEVEL\", \"INFO\")\n",
    "logging.basicConfig(level=LOG_LEVEL, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Max input size for LLM prompt (characters). Can be overridden via env var.\n",
    "MAX_INPUT_CHARS = int(os.getenv(\"MAX_INPUT_CHARS\", \"30000\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-14T04:36:05.064141Z",
     "iopub.status.busy": "2025-10-14T04:36:05.063803Z",
     "iopub.status.idle": "2025-10-14T04:36:06.865450Z",
     "shell.execute_reply": "2025-10-14T04:36:06.864674Z",
     "shell.execute_reply.started": "2025-10-14T04:36:05.064114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 08:36:47,400 INFO: Text from Screenshot 2025-11-18 083442.png:\n",
      "2025-11-18 08:36:47,400 INFO: --------------------------------------------------\n",
      "2025-11-18 08:36:47,806 INFO: Text from Screenshot 2025-11-18 083507.png:\n",
      "2025-11-18 08:36:47,807 INFO: --------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./Data\"\n",
    "\n",
    "# Allow overriding tesseract command via environment variable (Windows)\n",
    "tess_cmd = os.getenv(\"TESSERACT_CMD\")\n",
    "if tess_cmd:\n",
    "    pytesseract.pytesseract.tesseract_cmd = tess_cmd\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            text = pytesseract.image_to_string(image)\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Text from {filename}:\")\n",
    "        logger.debug(text)\n",
    "        logger.info(\"-\" * 50)\n",
    "        # Append OCR output so all images' text is collected\n",
    "        all_texts.append(text)\n",
    "\n",
    "text = \"\\n\".join([t for t in all_texts if t and t.strip()])\n",
    "\n",
    "# Truncate very long inputs to avoid exceeding LLM token limits\n",
    "if len(text) > MAX_INPUT_CHARS:\n",
    "    # Truncate at the last newline before the limit if possible\n",
    "    cutoff = text.rfind(\"\\n\", 0, MAX_INPUT_CHARS)\n",
    "    if cutoff == -1:\n",
    "        cutoff = MAX_INPUT_CHARS\n",
    "    logger.warning(f\"OCR text exceeds MAX_INPUT_CHARS ({MAX_INPUT_CHARS}). Truncating to {cutoff} chars.\")\n",
    "    text = text[:cutoff]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T04:36:06.970856Z",
     "iopub.status.busy": "2025-10-14T04:36:06.970672Z",
     "iopub.status.idle": "2025-10-14T04:36:13.894120Z",
     "shell.execute_reply": "2025-10-14T04:36:13.893358Z",
     "shell.execute_reply.started": "2025-10-14T04:36:06.970842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bd Calling\\AppData\\Local\\Temp\\ipykernel_15484\\3587795356.py:103: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = client(messages)\n",
      "2025-11-18 08:36:54,848 INFO: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-18 08:36:54,971 INFO: ✅ Project proposal created successfully: project_proposal.docx\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DOCX = \"project_proposal.docx\"\n",
    "\n",
    "prompt_text = f\"\"\"\n",
    "You are an expert project analyst. Your task is to read the text below and create a complete, structured project proposal.\n",
    "STRICTLY OUTPUT VALID JSON ONLY, using the exact template provided. \n",
    "DO NOT include any explanations, notes, or text outside the JSON.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "1. Every field that is a list (Objectives, Goals, Expected Outcomes, Success Metrics, Core Features, Core Features & Functionalities, Tech Stack, Integration Needs, Security & Compliance, Performance Criteria, App Flow Summary, Deliverables, Milestones, Team Roles, Dependencies, Potential Risks, Mitigation Strategies) MUST be a proper JSON array of strings. \n",
    "2. Fields that are single values (Project Title, Client Name, Project Summary, Target Audience, Monetization Strategy, Estimated Duration, Estimated Budget, Estimated Timeline & Pricing, Other Notes) MUST be strings.\n",
    "3. Nested dictionaries (like Cost Breakdown under Budget & Costing) must have string keys and string or number values.\n",
    "4. Ensure all sections are filled logically based on the input text. If no information is present, leave the field empty (\"\" for strings, [] for lists, {{}} for dictionaries).\n",
    "5. Avoid any extra formatting, markdown, or comments.\n",
    "6. Follow this **exact JSON template structure**:\n",
    "\n",
    "{{\n",
    "    \"Project Overview\": {{\n",
    "        \"Project Title\": \"\",\n",
    "        \"Client Name\": \"\",\n",
    "        \"Project Summary\": \"\",\n",
    "        \"Objectives\": []\n",
    "    }},\n",
    "    \"Business Requirements\": {{\n",
    "        \"Goals\": [],\n",
    "        \"Target Audience\": \"\",\n",
    "        \"Expected Outcomes\": [],\n",
    "        \"Success Metrics\": [],\n",
    "        \"Monetization Strategy\": \"\"\n",
    "    }},\n",
    "    \"Technical Requirements\": {{\n",
    "        \"Core Features\": [],\n",
    "        \"Core Features & Functionalities\": [],\n",
    "        \"Tech Stack\": [],\n",
    "        \"Integration Needs\": [],\n",
    "        \"Security & Compliance\": [],\n",
    "        \"Performance Criteria\": []\n",
    "    }},\n",
    "    \"App Flow\": {{\n",
    "        \"App Flow Summary\": []\n",
    "    }},\n",
    "    \"Project Scope\": {{\n",
    "        \"Inclusions\": [],\n",
    "        \"Exclusions\": [],\n",
    "        \"Deliverables\": [],\n",
    "        \"Milestones\": [],\n",
    "        \"Estimated Timeline & Pricing\": \"\"\n",
    "    }},\n",
    "    \"Timeline & Resources\": {{\n",
    "        \"Estimated Duration\": \"\",\n",
    "        \"Team Roles\": [],\n",
    "        \"Dependencies\": []\n",
    "    }},\n",
    "    \"Budget & Costing\": {{\n",
    "        \"Estimated Budget\": \"\",\n",
    "        \"Cost Breakdown\": {{}}\n",
    "    }},\n",
    "    \"Risk Assessment\": {{\n",
    "        \"Potential Risks\": [],\n",
    "        \"Mitigation Strategies\": []\n",
    "    }},\n",
    "    \"Other Notes\": \"\"\n",
    "}}\n",
    "\n",
    "Text to analyze:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "messages = [HumanMessage(content=prompt_text)]\n",
    "\n",
    "import time\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY environment variable not set!\")\n",
    "\n",
    "client = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=1.5,\n",
    ")\n",
    "\n",
    "def extract_first_json(s: str):\n",
    "    \"\"\"Extract the first balanced JSON object from a string. Returns the JSON substring or None.\"\"\"\n",
    "    s = s.strip()\n",
    "    start = None\n",
    "    brace_count = 0\n",
    "    for i, ch in enumerate(s):\n",
    "        if ch == '{':\n",
    "            if start is None:\n",
    "                start = i\n",
    "            brace_count += 1\n",
    "        elif ch == '}':\n",
    "            brace_count -= 1\n",
    "            if brace_count == 0 and start is not None:\n",
    "                return s[start:i+1]\n",
    "    return None\n",
    "\n",
    "# Try calling the LLM with simple retry/backoff\n",
    "llm_output = None\n",
    "for attempt in range(3):\n",
    "    try:\n",
    "        response = client(messages)\n",
    "        llm_output = response.content.strip()\n",
    "        break\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"LLM call failed (attempt {attempt+1}): {e}\")\n",
    "        if attempt < 2:\n",
    "            time.sleep(2 ** attempt)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "try:\n",
    "    structured_output = json.loads(llm_output)\n",
    "except json.JSONDecodeError:\n",
    "    # fallback: extract first balanced JSON block\n",
    "    json_block = extract_first_json(llm_output or \"\")\n",
    "    if json_block:\n",
    "        try:\n",
    "            structured_output = json.loads(json_block)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(\"LLM returned JSON-like block but parsing failed: \" + str(e))\n",
    "    else:\n",
    "        # try fenced code block with JSON\n",
    "        fence_match = re.search(r\"```(?:json)?\\s*(\\{.*\\})\\s*```\", llm_output or \"\", re.DOTALL)\n",
    "        if fence_match:\n",
    "            structured_output = json.loads(fence_match.group(1))\n",
    "        else:\n",
    "            raise ValueError(\"Could not parse JSON from LLM output!\")\n",
    "\n",
    "# basic validation\n",
    "if not isinstance(structured_output, dict):\n",
    "    raise ValueError(\"Parsed structured_output is not a JSON object/dict!\")\n",
    "\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Project Proposal\", 0)\n",
    "\n",
    "def add_section(section_name, content):\n",
    "    \"\"\"Add a section to the Word document\"\"\"\n",
    "    doc.add_heading(section_name, level=1)\n",
    "    if not isinstance(content, dict):\n",
    "        doc.add_paragraph(str(content))\n",
    "        return\n",
    "    for key, value in content.items():\n",
    "        # Special handling for Budget & Costing\n",
    "        if section_name == \"Budget & Costing\":\n",
    "            if key == \"Estimated Budget\":\n",
    "                doc.add_heading(\"Estimated Budget\", level=2)\n",
    "                doc.add_paragraph(str(value))\n",
    "            elif key == \"Cost Breakdown\":\n",
    "                doc.add_heading(\"Cost Breakdown\", level=2)\n",
    "                if isinstance(value, dict) and value:\n",
    "                    table = doc.add_table(rows=1, cols=2)\n",
    "                    table.style = \"Light Grid\"\n",
    "                    hdr_cells = table.rows[0].cells\n",
    "                    hdr_cells[0].text = \"Item\"\n",
    "                    hdr_cells[1].text = \"Amount\"\n",
    "                    for item_name, amount in value.items():\n",
    "                        row_cells = table.add_row().cells\n",
    "                        row_cells[0].text = str(item_name)\n",
    "                        row_cells[1].text = str(amount)\n",
    "                else:\n",
    "                    doc.add_paragraph(\"No cost breakdown provided.\")\n",
    "            continue\n",
    "\n",
    "        doc.add_heading(key, level=2)\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                doc.add_paragraph(item, style=\"List Bullet\")\n",
    "        elif isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                doc.add_paragraph(f\"{sub_key}: {sub_value}\", style=\"List Bullet\")\n",
    "        else:\n",
    "            doc.add_paragraph(str(value))\n",
    "\n",
    "# Sections to include\n",
    "sections = [\n",
    "    \"Project Overview\",\n",
    "    \"Business Requirements\",\n",
    "    \"Technical Requirements\",\n",
    "    \"App Flow\",\n",
    "    \"Project Scope\",\n",
    "    \"Timeline & Resources\",\n",
    "    \"Budget & Costing\",\n",
    "    \"Risk Assessment\"\n",
    "]\n",
    "\n",
    "for section in sections:\n",
    "    content = structured_output.get(section, {})\n",
    "    if content:\n",
    "        add_section(section, content)\n",
    "\n",
    "# Other Notes\n",
    "other_notes = structured_output.get(\"Other Notes\", \"\")\n",
    "if other_notes:\n",
    "    doc.add_heading(\"Other Notes\", level=1)\n",
    "    doc.add_paragraph(other_notes)\n",
    "\n",
    "# Save Document\n",
    "# Final validation: ensure at least one section was written\n",
    "if not any(structured_output.get(s) for s in sections):\n",
    "    logger.warning(\"No recognised sections found in LLM output; saving whatever was returned.\")\n",
    "\n",
    "try:\n",
    "    doc.save(OUTPUT_DOCX)\n",
    "    logger.info(f\"✅ Project proposal created successfully: {OUTPUT_DOCX}\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Failed to save document: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using live LLM response (structured_output as parsed earlier).\n",
      "Structured output validated with pydantic.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bd Calling\\AppData\\Local\\Temp\\ipykernel_15484\\1497845967.py:54: PydanticDeprecatedSince20: The `parse_obj` method is deprecated; use `model_validate` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  validated = RootModel.parse_obj(structured_output)\n"
     ]
    }
   ],
   "source": [
    "# === Validation & Local Test Helpers ===\n",
    "# Optional: use pydantic to validate the LLM output structure and provide defaults\n",
    "try:\n",
    "    from pydantic import BaseModel, Field\n",
    "except Exception:\n",
    "    print(\"pydantic not installed. Install with: pip install pydantic\")\n",
    "    BaseModel = object\n",
    "    Field = lambda *a, **k: None\n",
    "\n",
    "class ProjectOverviewModel(BaseModel):\n",
    "    Project_Title: str = Field(\"\", alias=\"Project Title\")\n",
    "    Client_Name: str = Field(\"\", alias=\"Client Name\")\n",
    "    Project_Summary: str = Field(\"\", alias=\"Project Summary\")\n",
    "    Objectives: list[str] = Field(default_factory=list, alias=\"Objectives\")\n",
    "\n",
    "class RootModel(BaseModel):\n",
    "    Project_Overview: dict = Field(default_factory=dict, alias=\"Project Overview\")\n",
    "    Business_Requirements: dict = Field(default_factory=dict, alias=\"Business Requirements\")\n",
    "    Technical_Requirements: dict = Field(default_factory=dict, alias=\"Technical Requirements\")\n",
    "    App_Flow: dict = Field(default_factory=dict, alias=\"App Flow\")\n",
    "    Project_Scope: dict = Field(default_factory=dict, alias=\"Project Scope\")\n",
    "    Timeline_Resources: dict = Field(default_factory=dict, alias=\"Timeline & Resources\")\n",
    "    Budget_Costing: dict = Field(default_factory=dict, alias=\"Budget & Costing\")\n",
    "    Risk_Assessment: dict = Field(default_factory=dict, alias=\"Risk Assessment\")\n",
    "    Other_Notes: str = Field(\"\", alias=\"Other Notes\")\n",
    "\n",
    "# MOCK mode for local testing without calling the LLM\n",
    "MOCK_LLM = False\n",
    "MOCK_RESPONSE = {\n",
    "    \"Project Overview\": {\n",
    "        \"Project Title\": \"Sample Project\",\n",
    "        \"Client Name\": \"ACME Corp\",\n",
    "        \"Project Summary\": \"A sample project for testing.\",\n",
    "        \"Objectives\": [\"Test OCR\", \"Generate docx\"]\n",
    "    },\n",
    "    \"Business Requirements\": {\n",
    "        \"Goals\": [\"Goal A\"],\n",
    "        \"Target Audience\": \"Developers\",\n",
    "        \"Expected Outcomes\": [\"Outcome 1\"],\n",
    "        \"Success Metrics\": [\"Metric 1\"],\n",
    "        \"Monetization Strategy\": \"Subscription\"\n",
    "    }\n",
    "}\n",
    "\n",
    "if MOCK_LLM:\n",
    "    structured_output = MOCK_RESPONSE\n",
    "    print(\"Using MOCK LLM response for testing.\")\n",
    "else:\n",
    "    print(\"Using live LLM response (structured_output as parsed earlier).\")\n",
    "\n",
    "# If pydantic available, validate\n",
    "if BaseModel is not object:\n",
    "    try:\n",
    "        validated = RootModel.parse_obj(structured_output)\n",
    "        print(\"Structured output validated with pydantic.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Validation warning: {e}\")\n",
    "\n",
    "# You can re-run the doc generation cells now to test with MOCK_RESPONSE\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8487016,
     "sourceId": 13377106,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
